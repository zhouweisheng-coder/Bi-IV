# Thinking1  如何使用用户标签来指导业务（如何提升业务）能用自己的语言总结标签对业务的作用（10points）

### 根据公司的战略角度：

1. **提高运营效率**：利用标签构建产品的用户画像，利用现有的用户画像做好存量用户的维护，通过精准营销策略，提升存量用户的留存与活跃。

2. **有利于产品设计**：基于用户画像，才可以进行精准人群的需求分析和功能设计，更加容易得到用户的认可，更容易打造产品亮点，提供精准个性化服务，如个性化推荐。

3. **公司战略影响**：有了用户标签，基于用户画像，可以及时的洞察市场走向，预测产品所占市场规模及发展前景，以及时优化公司战略，避免过早陷入发展瓶颈；并且可以利用大量的用户数据，便于孵化创新产品，丰富盈利模式。

### 根据用户生命周期的三个阶段：

1. 获客：如何进行拉新，通过更精准的营销获取客户；

2. 粘客：个性化推荐，搜索排序，场景运营等；

3. 留客：流失率预测，分析关键节点降低流失率。

# Thinking2  如果给你一堆用户数据，没有打标签。你该如何处理（如何打标签）  能列举对于数据打标签的方法（10points） 

* 人工标记，专家标记
* 常用聚类算法包括K-Means、EM、GMM、DBSCAN、及降维算法PCA

# Thinking3  准确率和精确率有何不同（评估指标）      对不同评估指标的作用理解（10points）  

![image-20200908140252798](C:\Users\Zhou\AppData\Roaming\Typora\typora-user-images\image-20200908140252798.png)

TP: Ture Positive 把正的判断为正的数目 True Positive,判断正确，且判为了正，即正的预测为正的。 

FN: False Negative 把正的错判为负的数目 False Negative,判断错误，且判为了负，即把正的判为了负的 

FP: False Positive 把负的错判为正的数目 False Positive, 判断错误，且判为了正，即把负的判为了正的 

TN: True Negative 把负的判为负的数目 True Negative,判断正确，且判为了负，即把负的判为了负的

1. 精确率(Precision) 精确率是相对于**预测结果**而言的，它表示的是**预测为正的样本中有多少是对的**；那么预测为正的样本就有两种可能来源，一种是把正的预测为正的，这类有TruePositive个, 另外一种是把负的错判为正的，这类有FalsePositive个，因此精确率即：P=TP/(TP+FP)
2. 准确率 (Accuracy) 准确率是指有在所有的判断中有多少判断正确的，即把**正的判断为正的，还有把负的判断为负**的；总共有 TP + FN + FP + TN 个，所以准确率：(TP+TN) / (TP+TN+FN+FP)
3. 召回率 (Recall) 召回率是相对于**样本**而言的，即**实际样本中有多少正样本被预测正确了**，这样的有TP个，所有的正样本有两个去向，一个是被判为正的，另一个是错判为负的，因此总共有TP+FN个，所以，召回率 R= TP / (TP+FN)

# Thinking4  如果你使用大众点评，想要给某个餐厅打标签。这时系统可以自动提示一些标签，你会如何设计（标签推荐）  针对标签推荐的场景，能简要说明设计标签推荐的原理（10points）  

* 方法1：给用户u推荐整个系统最热门的标签

* 方法2：给用户u推荐物品i上最热门的标签

* 方法3：给用户u推荐他自己经常使用的标签

* 将方法2和3进行加权融合，生成最终的标签推荐结果  

### 原理：

1. 为每个item抽取出features；
2. 利用一个用户过去喜欢（不喜欢）的item的特征数据，来学习该用户的喜好特征（profile），可以利用协同过滤算法、关联分析等；
3. 通过用户profile与候选item的特征，推荐相关性最大的item，也就是topN。

# Thinking5  我们今天使用了10种方式来解MNIST，这些方法有何不同？你还有其他方法来解决MNIST识别问题么（分类方法）  1、能理解不同分类算法的差异（10points）     2、能列举出其他的算法，解决 MNIST问题（10points）  

## 1、各算法简介：

1. LR：逻辑回归，简单且高效的方法。不能很好地处理大量多类特征或变量；

2. CART、ID3：决策树方法，分别用gini和信息增益作为指标调整分类器，是树模型，易于解释。

3. LDA：是主题模型

4. 朴素贝叶斯：假设每个输入变量是独立的，简单且强大的预测建模算法。对小规模的数据表现很好，能个处理多分类任务，适合增量式训练；对缺失数据不太敏感，算法也比较简单，常用于文本分类。

5. SVM：高准确率，为避免过拟合提供了很好的理论保证，而且就算数据在原特征空间线性不可分，只要给个合适的核函数，它就能运行得很好。在动辄超高维的文本分类问题中特别受欢迎。可惜内存消耗大，难以解释，运行和调参也有些烦人。

6. KNN：理论成熟，思想简单，既可以用来做分类也可以用来做回归；样本不平衡问题。

7. Adaboost：是一种加和模型，每个模型都是基于上一次模型的错误率来建立的，过分关注分错的样本，而对正确分类的样本减少关注度，逐次迭代之后，可以得到一个相对较好的模型。是一种典型的boosting算法。

8. XGBoost：Boosting是一种常用的统计学习方法，在训练过程中，通过改变训练样本的权重，学习多个分类器，最终获得最优分类器。xgBoosting在传统Boosting的基础上，利用cpu的多线程，引入正则化项，加入剪枝，控制了模型的复杂度。

9. TPOT：自动机器学习方法，能找到机器学习比较好的模型，但是需要花费更多的算力。

10. keras：神经网络框架。利用神经网络能更加精确的无限逼近目标值。但是需要算力较大。

## 2、其他算法解决mnist

* ML：RandomForest、catboost、lightGBM
* DL：CNN、LSTM等


## 3、算法选择参考

之前翻译过一些国外的文章，有一篇文章中给出了一个简单的算法选择技巧：

1. 首当其冲应该选择的就是逻辑回归，如果它的效果不怎么样，那么可以将它的结果作为基准来参考，在基础上与其他算法进行比较；

2. 然后试试决策树（随机森林）看看是否可以大幅度提升你的模型性能。即便最后你并没有把它当做为最终模型，你也可以使用随机森林来移除噪声变量，做特征选择；

3. 如果特征的数量和观测样本特别多，那么当资源和时间充足时（这个前提很重要），使用SVM不失为一种选择。

通常情况下：【GBDT>=SVM>=RF>=Adaboost>=Other…】，现在深度学习很热门，很多领域都用到，它是以神经网络为基础的。

算法固然重要，**但好的数据却要优于好的算法**，设计优良特征是大有裨益的。假如你有一个超大数据集，那么无论你使用哪种算法可能对分类性能都没太大影响（此时就可以根据速度和易用性来进行抉择）。

# Action1  针对Delicious数据集，对SimpleTagBased算法进行改进（使用NormTagBased、TagBased-TFIDF算法）  Delicious    完成代码，结果正确（20points）    

# Action2  对Titanic数据进行清洗，建模并对乘客生存进行预测。使用之前介绍过的10种模型中的至少2种（包括TPOT）  Titanic    1、完成代码，结果正确（20points）     2、能使用TPOT完成预测（20points）  

